{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "# directory: ./data/*/*.nii.gz\n",
    "# there are different modalities that should be taken care of\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, moda):\n",
    "        self.moda = moda\n",
    "        # [\"FLAIR_preprocessed\", \"T1_preprocessed\", \"T2_preprocessed\"]\n",
    "        self.input = {m : defaultdict(list) for m in self.moda}\n",
    "        self.target = defaultdict(list)\n",
    "        self.kfold = None\n",
    "        self.batch_size = None\n",
    "        self.patch_size = None\n",
    "        self.patch_gap = None\n",
    "        self.patch_index = defaultdict(list)\n",
    "        self.valid_index = {}\n",
    "        # pre-set seed so that reconstruct can retrieve valid_index for final result\n",
    "        random.seed(3000)\n",
    "        \n",
    "    def fetch_raw_data_from_file(self, modality, file_name):\n",
    "        def fetch_file(modality):\n",
    "            # could be \"Consensus\", \"FLAIR_preprocessed\"\n",
    "            data = []\n",
    "            root, sub_dir, _ = next(os.walk(os.getcwd() + '/data/'))\n",
    "            for sub in sub_dir:\n",
    "                data.append(os.path.join(root, sub + '/' + modality + '.nii.gz'))\n",
    "            return data\n",
    "        file = fetch_file(modality)\n",
    "        raw_data = defaultdict(list)\n",
    "        for i in range(len(file)):\n",
    "            image = nib.load(file[i])\n",
    "            raw_data[image.shape].append(image.get_fdata())\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            for i in raw_data:\n",
    "                f.create_dataset(str(i), data=raw_data[i])\n",
    "        return raw_data\n",
    "    \n",
    "    def zero_pad(self, image, div=(32, 32, 32)):\n",
    "        pad_size = [0, 0, 0]\n",
    "        pad = False\n",
    "        for i in range(len(image.shape)):\n",
    "            remain = image.shape[i] % div[i]\n",
    "            if remain != 0:\n",
    "                pad = True\n",
    "                pad_size[i] = (image.shape[i] // div[i] + 1) * div[i] - image.shape[i]\n",
    "        if pad:\n",
    "            # deal with odd number of padding\n",
    "            pad0 = (pad_size[0]//2, pad_size[0] - pad_size[0]//2)\n",
    "            pad1 = (pad_size[1]//2, pad_size[1] - pad_size[1]//2)\n",
    "            pad2 = (pad_size[2]//2, pad_size[2] - pad_size[2]//2)\n",
    "            # https://stackoverflow.com/questions/50008587/zero-padding-a-3d-numpy-array\n",
    "            return np.pad(image, (pad0, pad1, pad2), 'constant')\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def check_file_exist(self, path, pattern):\n",
    "        for m in self.moda:\n",
    "            if not os.path.isfile(path + pattern + m + '.h5'):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def fetch_target_data(self, target_path):\n",
    "        self.fetch_raw_data_from_file('Consensus', target_path + 'target_data.h5')\n",
    "        return self.load_target_data(target_path)\n",
    "    \n",
    "    def fetch_raw_data(self, raw_path):\n",
    "        for m in self.moda:\n",
    "            # different modality: same order of images\n",
    "            self.fetch_raw_data_from_file(m, raw_path + 'raw_data_' + m + '.h5')\n",
    "        return self.load_raw_data(raw_path)\n",
    "    \n",
    "    def load_target_data(self, target_path):\n",
    "        target_file = h5py.File(target_path + 'target_data.h5', 'r')\n",
    "        target_data = defaultdict(list)\n",
    "        for i in target_file.keys():\n",
    "            target_data[i] = target_file[i]\n",
    "        return target_data, target_file\n",
    "    \n",
    "    def load_raw_data(self, raw_path):\n",
    "        raw_file = []\n",
    "        raw_data = {m : defaultdict(list) for m in self.moda}\n",
    "        for m in self.moda:\n",
    "            data = defaultdict(list)\n",
    "            file = h5py.File(raw_path + 'raw_data_' + m + '.h5', 'r') \n",
    "            raw_file.append(file)\n",
    "            for i in file.keys():\n",
    "                # to get the matrix: self.data[i][:]\n",
    "                # d.data[i][j][0], d.data[i][j][1]\n",
    "                data[i] = file[i]\n",
    "            raw_data[m] = data\n",
    "        return raw_data, raw_file\n",
    "    \n",
    "        # raw_data:\n",
    "        # {'FLAIR_preprocessed': defaultdict(list,\n",
    "        #               {'(128, 224, 256)': <HDF5 dataset \"(128, 224, 256)\": shape (5, 128, 224, 256), type \"<f8\">,\n",
    "        #                '(144, 512, 512)': <HDF5 dataset \"(144, 512, 512)\": shape (5, 144, 512, 512), type \"<f8\">,\n",
    "        #                '(261, 336, 336)': <HDF5 dataset \"(261, 336, 336)\": shape (5, 261, 336, 336), type \"<f8\">}),\n",
    "        #   'T1_preprocessed': defaultdict(list,\n",
    "        #               {'(128, 224, 256)': <HDF5 dataset \"(128, 224, 256)\": shape (5, 128, 224, 256), type \"<f8\">,\n",
    "        #                '(144, 512, 512)': <HDF5 dataset \"(144, 512, 512)\": shape (5, 144, 512, 512), type \"<f8\">,\n",
    "        #                '(261, 336, 336)': <HDF5 dataset \"(261, 336, 336)\": shape (5, 261, 336, 336), type \"<f8\">}),\n",
    "        #   'T2_preprocessed': defaultdict(list,\n",
    "        #               {'(128, 224, 256)': <HDF5 dataset \"(128, 224, 256)\": shape (5, 128, 224, 256), type \"<f8\">,\n",
    "        #                '(144, 512, 512)': <HDF5 dataset \"(144, 512, 512)\": shape (5, 144, 512, 512), type \"<f8\">,\n",
    "        #                '(261, 336, 336)': <HDF5 dataset \"(261, 336, 336)\": shape (5, 261, 336, 336), type \"<f8\">})}\n",
    "        # raw_file:\n",
    "        #  [<HDF5 file \"raw_data_FLAIR_preprocessed.h5\" (mode r)>,\n",
    "        #   <HDF5 file \"raw_data_T1_preprocessed.h5\" (mode r)>,\n",
    "        #   <HDF5 file \"raw_data_T2_preprocessed.h5\" (mode r)>]\n",
    "\n",
    "    def pad_target_data(self, patch_size, pad_path, target_path):\n",
    "        # input\n",
    "        target_data = None\n",
    "        target_file = None\n",
    "        if os.path.isfile(target_path + \"target_data.h5\"):\n",
    "            target_data, target_file = self.load_target_data(target_path)\n",
    "        else:\n",
    "            target_data, target_file = self.fetch_target_data(target_path)\n",
    "        \n",
    "        pad_target_data = defaultdict(list)\n",
    "        for i in target_data.keys():\n",
    "            for j in range(target_data[i].shape[0]):\n",
    "                img = self.zero_pad(target_data[i][j], patch_size)\n",
    "                pad_target_data[img.shape].append(img)\n",
    "\n",
    "        target_file.close()\n",
    "\n",
    "        with h5py.File(pad_path + \"pad_target_data.h5\" , 'w') as f:\n",
    "            f.create_dataset(\"patch_size\", data=patch_size)\n",
    "            for i in pad_target_data:\n",
    "                f.create_dataset(str(i), data=pad_target_data[i])\n",
    "        \n",
    "        pad_file = h5py.File(pad_path + \"pad_target_data.h5\" , 'r')\n",
    "        for i in pad_file.keys():\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            self.target[i] = pad_file[i][:]\n",
    "        \n",
    "    def pad_raw_data(self, patch_size, pad_path, raw_path):\n",
    "        # input\n",
    "        raw_data = None\n",
    "        raw_file = None\n",
    "        if self.check_file_exist(raw_path, \"raw_data_\"):\n",
    "            raw_data, raw_file = self.load_raw_data(raw_path)\n",
    "        else:\n",
    "            raw_data, raw_file = self.fetch_raw_data(raw_path)\n",
    "        \n",
    "        pad_data = {m : defaultdict(list) for m in self.moda}\n",
    "        for m in raw_data.keys():\n",
    "            data = defaultdict(list)\n",
    "            for i in raw_data[m].keys():\n",
    "                for j in range(raw_data[m][i].shape[0]):\n",
    "                    img = self.zero_pad(raw_data[m][i][j], patch_size)\n",
    "                    data[img.shape].append(img)\n",
    "            pad_data[m] = data\n",
    "            \n",
    "        for f in raw_file:\n",
    "            f.close()\n",
    "\n",
    "        for m in pad_data.keys():\n",
    "            with h5py.File(pad_path + \"pad_data_\" + m + \".h5\" , 'w') as f:\n",
    "                f.create_dataset(\"patch_size\", data=patch_size)\n",
    "                for i in pad_data[m]:\n",
    "                    f.create_dataset(str(i), data=pad_data[m][i])\n",
    "        \n",
    "        for m in pad_data.keys():\n",
    "            pad_file = h5py.File(pad_path + \"pad_data_\" + m + \".h5\" , 'r')\n",
    "            for i in pad_file.keys():\n",
    "                if i == \"patch_size\":\n",
    "                    continue\n",
    "                self.input[m][i] = pad_file[i][:]\n",
    "        \n",
    "    \n",
    "    def load_data(self, patch_size=(32, 32, 32), \n",
    "                  pad_path=\"./model/h5df_data/\", raw_path=\"./model/h5df_data/\", target_path=\"./model/h5df_data/\"):\n",
    "                  # pad_path=\"./model/h5df_data/pad_data.h5\", raw_path=\"./model/h5df_data/raw_data.h5\"):\n",
    "        padded = True\n",
    "        if self.check_file_exist(raw_path, \"pad_data_\"):\n",
    "            for m in self.moda:\n",
    "                pad_file = h5py.File(pad_path + \"pad_data_\" + m + \".h5\", 'r')\n",
    "                if np.all(pad_file[\"patch_size\"][:] == list(patch_size)):\n",
    "                    # self.data = pad_file[\"pad_data\"]\n",
    "                    for i in pad_file.keys():\n",
    "                        self.input[m][i] = pad_file[i][:]\n",
    "                else:\n",
    "                    padded = False\n",
    "                    break\n",
    "        else:\n",
    "            padded = False\n",
    "        if padded == False:\n",
    "            self.pad_raw_data(patch_size, pad_path, raw_path)\n",
    "        \n",
    "        if os.path.isfile(target_path + \"pad_target_data.h5\"):\n",
    "            pad_file = h5py.File(target_path + \"pad_target_data.h5\", 'r')\n",
    "            if np.all(pad_file[\"patch_size\"][:] == list(patch_size)):\n",
    "                # self.data = pad_file[\"pad_data\"]\n",
    "                for i in pad_file.keys():\n",
    "                    self.target[i] = pad_file[i][:]\n",
    "            else:\n",
    "                self.pad_target_data(patch_size, pad_path, target_path)\n",
    "        else:\n",
    "            self.pad_target_data(patch_size, pad_path, target_path)\n",
    "    \n",
    "    ################################################################################\n",
    "    \n",
    "    def gen_patch_index(self, patch_size, patch_gap, patch_path):\n",
    "        count = 0\n",
    "        patch_index = defaultdict(list)\n",
    "        # https://arxiv.org/pdf/1710.02316.pdf  at least 0.01% voxels contain lesions\n",
    "        voxel = int(patch_size[0]*patch_size[1]*patch_size[2]*0.0001)\n",
    "        \n",
    "        # patches of segmentation\n",
    "        for i in self.target:\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            shape = self.target[i][0].shape\n",
    "            patch_num = [int((shape[i]-patch_size[i]) / patch_gap) for i in range(len(shape))]\n",
    "            for j in range(self.target[i].shape[0]):\n",
    "                patch_ind = []\n",
    "                # assume this is a 3d image\n",
    "                for a in range(patch_num[0]):\n",
    "                    for b in range(patch_num[1]):\n",
    "                        for c in range(patch_num[2]):\n",
    "                            patch_iter = [a * patch_gap, b * patch_gap, c * patch_gap, 1]\n",
    "                            if (np.sum(self.target[i][j][\n",
    "                                patch_iter[0]:patch_iter[0] + patch_size[0],\n",
    "                                patch_iter[1]:patch_iter[1] + patch_size[1],\n",
    "                                patch_iter[2]:patch_iter[2] + patch_size[2]]) <= voxel):\n",
    "                                # 0: does not satisfy, need to skip when generating\n",
    "                                patch_iter[3] = 0\n",
    "                            patch_ind.append(patch_iter)\n",
    "                count += len(patch_ind)\n",
    "                patch_index[i].append(patch_ind)\n",
    "            for c in range(len(patch_index[i])):\n",
    "                np.random.shuffle(patch_index[i][c]) # in-place shuffule\n",
    "        \n",
    "        with h5py.File(patch_path + \"pad_patch_index.h5\", 'w') as f:\n",
    "            f.create_dataset(\"count\", data=count)\n",
    "            f.create_dataset(\"patch_size\", data=patch_size)\n",
    "            f.create_dataset(\"patch_gap\", data=patch_gap)\n",
    "            for i in patch_index:\n",
    "                f.create_dataset(str(i), data=patch_index[i])\n",
    "        \n",
    "        index_file = h5py.File(patch_path + \"pad_patch_index.h5\", 'r')\n",
    "        for i in index_file.keys():\n",
    "            if i == \"count\" or i == \"patch_size\" or i == \"patch_gap\":\n",
    "                continue\n",
    "            self.patch_index[i] = index_file[i][:]\n",
    "        # return the total number of patches\n",
    "        return index_file[\"count\"][()]\n",
    "\n",
    "    \n",
    "    def load_patch_index(self, patch_size, patch_gap, patch_path):\n",
    "        if os.path.isfile(patch_path + \"pad_patch_index.h5\"):\n",
    "            index_file = h5py.File(patch_path + \"pad_patch_index.h5\", 'r')\n",
    "            # print(list(pat_ind.keys()))\n",
    "            if (np.all(index_file[\"patch_size\"][:] == list(patch_size))) and (index_file[\"patch_gap\"][()] == patch_gap):\n",
    "                for i in index_file.keys():\n",
    "                    if i == \"count\" or i == \"patch_size\" or i == \"patch_gap\":\n",
    "                        continue\n",
    "                    self.patch_index[i] = index_file[i][:]\n",
    "                return index_file[\"count\"][()]\n",
    "            else:\n",
    "                index_file.close()\n",
    "                return self.gen_patch_index(patch_size, patch_gap, patch_path)\n",
    "        else:\n",
    "            return self.gen_patch_index(patch_size, patch_gap, patch_path)\n",
    "            \n",
    "    def prekfold(self, patch_size, patch_gap, batch_size, kfold=5, patch_path='./model/h5df_data/'):\n",
    "        self.kfold = kfold\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_gap = patch_gap\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # initialize validation index for training\n",
    "        # K-fold LOOCV: leave one out cross validation\n",
    "        for i in self.target:\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            self.valid_index[i] = random.sample(range(self.kfold), self.kfold)\n",
    "\n",
    "        num = self.load_patch_index(patch_size, patch_gap, patch_path)\n",
    "        train_num = num // self.kfold * (self.kfold - 1)\n",
    "        valid_num = num - train_num\n",
    "        \n",
    "        return train_num // batch_size, valid_num // batch_size\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.00001; multi-modality training on selected patch; dice loss; FLAIR only\n",
      "26496 6624\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 1/10\n",
      "  654/26496 [..............................] - ETA: 3:52:17 - loss: 0.9687 - dice_coefficient: 0.0313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5a93195f6f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m                             verbose=1)\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-5a93195f6f38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, data, train_generator, valid_generator, train_num, valid_num)\u001b[0m\n\u001b[1;32m     71\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                             verbose=1)\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/scratch/yl4217/MS-Lesion-Segmentation/\")\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "# config[\"modality\"] = [\"FLAIR_preprocessed\", \"T1_preprocessed\", \"T2_preprocessed\"]\n",
    "config[\"modality\"] = [\"FLAIR_preprocessed\"]\n",
    "\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 2\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "config[\"input_shape\"] = (len(config[\"modality\"]), None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "# config[\"initial_learning_rate\"] = 0.000001\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 10\n",
    "\n",
    "# from model.multi_data import *\n",
    "from model.multi_generator import *\n",
    "from model.modelDice import *\n",
    "\n",
    "d = Data(config[\"modality\"])\n",
    "d.load_data(config[\"patch_size\"])\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])\n",
    "\n",
    "train_generator = DataGenerator(d.moda, d.input, d.target, d.patch_index, d.kfold, d.batch_size,\n",
    "                                d.patch_size, d.patch_gap, d.valid_index, True)\n",
    "valid_generator = DataGenerator(d.moda, d.input, d.target, d.patch_index, d.kfold, d.batch_size,\n",
    "                                d.patch_size, d.patch_gap, d.valid_index, False)\n",
    "\n",
    "print(\"learning rate 0.00001; multi-modality training on selected patch; dice loss; FLAIR only\")\n",
    "\n",
    "def train(config, data, train_generator, valid_generator, train_num, valid_num):\n",
    "#     models = []\n",
    "    print(train_num, valid_num)\n",
    "    for i in range(data.kfold):\n",
    "        print ('-'*100)\n",
    "        print (\"Fold:\", i)\n",
    "\n",
    "        train_generator.set_index(i)\n",
    "        valid_generator.set_index(i)\n",
    "\n",
    "        model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "        callbacks = get_callbacks(config[\"weights_file\"], str(i)+'_dice_flair_multi_',\n",
    "                                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                                learning_rate_patience=config[\"patience\"],\n",
    "                                early_stopping_patience=config[\"early_stop\"])\n",
    "\n",
    "        model.fit_generator(generator=train_generator,\n",
    "                            steps_per_epoch=train_num,\n",
    "                            epochs=config[\"n_epochs\"],\n",
    "                            validation_data=valid_generator,\n",
    "                            validation_steps=valid_num,\n",
    "                            callbacks=callbacks,\n",
    "                            workers=2,\n",
    "                            verbose=1)\n",
    "        break\n",
    "train(config, d, train_generator, valid_generator, train_num, valid_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
