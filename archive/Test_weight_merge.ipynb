{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 10\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "config[\"input_shape\"] = (1, None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.data import *\n",
    "from model.model import *\n",
    "\n",
    "d = Data()\n",
    "d.load_data(config[\"patch_size\"])\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "# model.load_weights(os.getcwd() + '/model/weight/weights-01-0.02-0428-binary-patch.hdf5')\n",
    "\n",
    "# 0,0.9986013862178413,0.00427185765564637,0.9978142036170056,0.017498897570287473\n",
    "# model.load_weights(os.getcwd() + '/model/weight/fold-0-weights-04-0.34.hdf5')\n",
    "# model.load_weights(os.getcwd() + '/model/weight/fold-all_patch_0-weights-06-0.42.hdf5')\n",
    "model.load_weights(os.getcwd() + '/model/weight/fold0_all_patch_weights-02-0.34.hdf5') \n",
    "# model.load_weights(os.getcwd() + '/model/weight/fold-binary0-weights-06-0.02.hdf5')\n",
    "# model.load_weights(os.getcwd() + '/model/weight/dice/weights-03-0.31.hdf5')\n",
    "# model.load_weights(os.getcwd() + '/model/weight/binary/weights-01-0.02.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "# class Reconstruct:\n",
    "#     def __init__(self, ind, shape):\n",
    "#         # find its original image: d.data[str(shape)][ind][0]\n",
    "#         # find its target image: d.data[str(shape)][ind][1]\n",
    "#         self.ind = ind\n",
    "#         self.shape = shape\n",
    "#         self.data = np.zeros(shape)\n",
    "#         self.count = np.zeros(shape, dtype=np.int)\n",
    "        \n",
    "#     def add(self, patch, index):\n",
    "#         # get patch data\n",
    "#         patch_index = np.zeros(self.shape, dtype=np.bool)\n",
    "#         patch_index[...,\n",
    "#                     index[0]:index[0]+patch.shape[-3],\n",
    "#                     index[1]:index[1]+patch.shape[-2],\n",
    "#                     index[2]:index[2]+patch.shape[-1]] = True\n",
    "#         patch_data = np.zeros(self.shape)\n",
    "#         patch_data[patch_index] = patch.flatten()\n",
    "        \n",
    "#         # store patch data in self.data\n",
    "#         new_data_index = np.logical_and(patch_index, np.logical_not(self.count > 0))\n",
    "#         self.data[new_data_index] = patch_data[new_data_index]\n",
    "        \n",
    "#         # average overlapped region\n",
    "#         averaged_data_index = np.logical_and(patch_index, self.count > 0)\n",
    "#         if np.any(averaged_data_index):\n",
    "#             self.data[averaged_data_index] = (self.data[averaged_data_index] * self.count[averaged_data_index] + \n",
    "#                                               patch_data[averaged_data_index]) / (self.count[averaged_data_index] + 1)\n",
    "#         self.count[patch_index] += 1\n",
    "        \n",
    "    \n",
    "# result = []\n",
    "# fold_index = 0\n",
    "\n",
    "# for i in d.valid_index:\n",
    "#     j = d.valid_index[i][fold_index]\n",
    "#     recons = Reconstruct(j, d.data[i][j][0].shape)\n",
    "#     print(i)\n",
    "#     for ind in range(d.patch_index[i][j].shape[0]):\n",
    "#         index = d.patch_index[i][j][ind]\n",
    "#         image_i = np.expand_dims(d.data[i][j][0][\n",
    "#                          index[0]:index[0]+d.patch_size[0], \n",
    "#                          index[1]:index[1]+d.patch_size[1], \n",
    "#                          index[2]:index[2]+d.patch_size[2]], axis=0)\n",
    "#         recons.add(model.predict([image_i[None, :]]), index)\n",
    "\n",
    "#     result.append(copy.deepcopy(recons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.show_image([merge_image[None, None, :], merge_target[None, None, :], merge_result[None, None, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = []\n",
    "target = []\n",
    "result = []\n",
    "indices = []\n",
    "shape = []\n",
    "fold_index = 0\n",
    "for i in d.valid_index:\n",
    "    j = d.valid_index[i][fold_index]\n",
    "    indices.append(d.patch_index[i][j])\n",
    "    shape.append(d.data[i][j][0].shape)\n",
    "    for ind in range(d.patch_index[i][j].shape[0]):\n",
    "        patch = d.patch_index[i][j][ind]\n",
    "        image_i = np.expand_dims(d.data[i][j][0][patch[0]:patch[0]+d.patch_size[0], \n",
    "                         patch[1]:patch[1]+d.patch_size[1], \n",
    "                         patch[2]:patch[2]+d.patch_size[2]], axis=0)\n",
    "        target_i = np.expand_dims(d.data[i][j][1][patch[0]:patch[0]+d.patch_size[0], \n",
    "                         patch[1]:patch[1]+d.patch_size[1], \n",
    "                         patch[2]:patch[2]+d.patch_size[2]], axis=0)\n",
    "        image.append(image_i)\n",
    "        target.append(target_i)\n",
    "        result.append(model.predict([image_i[None, :]]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight pixel based on distance to boundary \n",
    "# draw dice vs threashold => get best threashold\n",
    "# calculate final dice after threashold\n",
    "\n",
    "\n",
    "\n",
    "def reconstruct_from_patches(patches, patch_indices, data_shape, default_value=0):\n",
    "    \"\"\"\n",
    "    Reconstructs an array of the original shape from the lists of patches and corresponding patch indices. Overlapping\n",
    "    patches are averaged.\n",
    "    :param patches: List of numpy array patches.\n",
    "    :param patch_indices: List of indices that corresponds to the list of patches.\n",
    "    :param data_shape: Shape of the array from which the patches were extracted.\n",
    "    :param default_value: The default value of the resulting data. if the patch coverage is complete, this value will\n",
    "    be overwritten.\n",
    "    :return: numpy array containing the data reconstructed by the patches.\n",
    "    \"\"\"\n",
    "    data = np.ones(data_shape) * default_value\n",
    "    image_shape = data_shape[-3:]\n",
    "    count = np.zeros(data_shape, dtype=np.int)\n",
    "    for patch, index in zip(patches, patch_indices):\n",
    "        image_patch_shape = patch.shape[-3:]\n",
    "        patch_index = np.zeros(data_shape, dtype=np.bool)\n",
    "        patch_index[...,\n",
    "                    index[0]:index[0]+patch.shape[-3],\n",
    "                    index[1]:index[1]+patch.shape[-2],\n",
    "                    index[2]:index[2]+patch.shape[-1]] = True\n",
    "        patch_data = np.zeros(data_shape)\n",
    "        \n",
    "        patch_data[patch_index] = patch.flatten()\n",
    "\n",
    "        new_data_index = np.logical_and(patch_index, np.logical_not(count > 0))\n",
    "        data[new_data_index] = patch_data[new_data_index]\n",
    "\n",
    "        averaged_data_index = np.logical_and(patch_index, count > 0)\n",
    "        if np.any(averaged_data_index):\n",
    "            data[averaged_data_index] = (data[averaged_data_index] * count[averaged_data_index] + patch_data[averaged_data_index]) / (count[averaged_data_index] + 1)\n",
    "        count[patch_index] += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_image = reconstruct_from_patches(image, indices[0], shape[0][-3:])\n",
    "merge_target = reconstruct_from_patches(target, indices[0], shape[0][-3:])\n",
    "merge_result = reconstruct_from_patches(result, indices[0], shape[0][-3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb05a31b7b14f90b3b943020b84daec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=64, description='id', max=127), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.show_image([merge_image[None, None, :], merge_target[None, None, :], merge_result[None, None, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8631411575921044\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(dice_coefficient(merge_target, merge_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = np.array(y_true).flatten()\n",
    "    y_pred_f = np.array(y_pred).flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    # tensorflow computation graph: will not configure print as one of the graph, unless using tf.Print()\n",
    "    return (2.*intersection+smooth) / (np.sum(y_true_f)+np.sum(y_pred_f)+smooth)\n",
    "# print(dice(merge_target, merge_result>0.02))\n",
    "\n",
    "it = np.arange(0, 1.01, 0.01)\n",
    "dice_thre = []\n",
    "for i in it:\n",
    "    dice_thre.append(dice(merge_target, merge_result>i))\n",
    "#     i += gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33 0.8813588255377262\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(it, dice_thre)\n",
    "print(it[np.argmax(dice_thre)], dice_thre[np.argmax(dice_thre)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = DataGenerator(d.data, d.patch_index, d.kfold, d.batch_size, \n",
    "                                d.patch_size, d.patch_gap, d.valid_index, False)\n",
    "valid_generator.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0680521a0fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(K.eval(dice_coefficient(tar, K.cast(model.predict(img, config[\"batch_size\"]), 'float64'))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdice_coeff\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnum_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/miniconda3/envs/mscond/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dice_coeff = 0\n",
    "num_iter = 0\n",
    "for img, tar in valid_generator:\n",
    "#     print(model.evaluate(img, tar, config[\"batch_size\"], verbose=0)[1])\n",
    "#     print(K.eval(dice_coefficient(tar, K.cast(model.predict(img, config[\"batch_size\"]), 'float64'))))\n",
    "#     break\n",
    "    dice_coeff += K.eval(dice_coefficient(tar, K.cast(model.predict(img, config[\"batch_size\"]),'float64')))\n",
    "    num_iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coeff /= num_iter\n",
    "print(dice_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_iter, valid_num, valid_generator.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./model/h5df_data/train_result_dice_0.84.h5\", 'w') as f:\n",
    "#     f.create_dataset(\"dice\", data=dice_coeff)\n",
    "    f.create_dataset(\"result\", data=[merge_image[None, None, :], merge_target[None, None, :], merge_result[None, None, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
