{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reference: https://github.com/ellisdg/3DUnetCNN/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"k_fold\"] = 5\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"batch_size\"] = 1\n",
    "config[\"input_shape\"] = (1, None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "# config[\"patch_shape\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (144, 512, 512)\n",
      "shape of data: (261, 336, 336)\n",
      "shape of data: (128, 224, 256)\n"
     ]
    }
   ],
   "source": [
    "from model.load_data_old import *\n",
    "from model.model import *\n",
    "\n",
    "d = Data()\n",
    "d.load_data()\n",
    "# display current shape of MRI images\n",
    "for i in d.data:\n",
    "    print(\"shape of data: {0}\".format(i))\n",
    "    \n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"k_fold\"], config[\"batch_size\"])\n",
    "d.preprocess(batch_size=config[\"batch_size\"], pool_size=config[\"pool_size\"], depth=config[\"depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 7s 597ms/step - loss: 0.2368 - dice_coefficient: 0.7632 - val_loss: 0.2009 - val_dice_coefficient: 0.7991\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "target = []\n",
    "image = []\n",
    "\n",
    "def train(config, data, train_num, valid_num):\n",
    "#     models = []\n",
    "\n",
    "    print(train_num, valid_num)\n",
    "    for i in range(data.kfold):\n",
    "        print ('-'*100)\n",
    "        print (\"Fold:\", i)\n",
    "        model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "        \n",
    "        # print(model.summary())\n",
    "        \n",
    "        callbacks = get_callbacks(config[\"weights_file\"],\n",
    "                                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                                learning_rate_patience=config[\"patience\"],\n",
    "                                early_stopping_patience=config[\"early_stop\"])\n",
    "\n",
    "        model.fit_generator(generator=data.train_generator(i, batch_size=config[\"batch_size\"]),\n",
    "                            steps_per_epoch=train_num,\n",
    "                            epochs=config[\"n_epochs\"],\n",
    "                            validation_data=data.valid_generator(i),\n",
    "                            validation_steps=valid_num,\n",
    "                            callbacks=callbacks,\n",
    "                            verbose = 1)\n",
    "        \n",
    "        for j in d.valid_index:\n",
    "            valid = d.data[j][i]\n",
    "            image.append(valid[i])\n",
    "            target.append(valid[i])\n",
    "            result.append(model.predict(np.array([valid[i]])))\n",
    "            \n",
    "        break\n",
    "\n",
    "        # models.append(model)\n",
    "\n",
    "train(config, d, train_num, valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391c43943714d338b9a41308bd42043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=16, description='id', max=31), Output()), _dom_classes=('widget-interactâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "def show_image(images):\n",
    "    def show_frame(id):\n",
    "        length = len(images)\n",
    "        for i in range(length):\n",
    "            plt.subplot(1, length, i+1)\n",
    "            plt.imshow(images[i][0, 0, id, :, :], cmap='gray')\n",
    "    interact(show_frame, id=widgets.IntSlider(min=0, max=images[0].shape[2]-1, step=1, value=images[0].shape[2]/2))\n",
    "\n",
    "sel = next(iter(d.valid_index))\n",
    "show_image([result[0], image[0][None, :, :, :, :], target[0][None, :, :, :, :]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice: 0.0029124265500517165\n",
      "loss: 0.9970875734499483\n",
      "0.0007326275284279208\n",
      "(3, 1, 1, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "dice = 0\n",
    "for i in range(len(result)):\n",
    "    dice += dice_coefficient(target[i], result[i])\n",
    "\n",
    "print(\"dice:\", dice / len(result))\n",
    "print(\"loss:\", 1 - dice / len(result)) \n",
    "\n",
    "print(dice_coefficient(target, result))\n",
    "print(np.array(result).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "#                               pool_size=config[\"pool_size\"],\n",
    "#                               initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "#                               deconvolution=config[\"deconvolution\"],\n",
    "#                               depth=config[\"depth\"],\n",
    "#                               n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "# model.load_weights(os.getcwd() + '/model/weight/weights-10--1.00.hdf5.h5')\n",
    "\n",
    "# for j in d.valid_index:\n",
    "#     valid = d.data[j][0] # fold = 0\n",
    "#     shape = valid[0].shape\n",
    "# #             x = shape[0] // 2\n",
    "# #             y = shape[1] // 2\n",
    "# #             z = shape[2] // 2\n",
    "# #             input = np.array([np.expand_dims(valid[0][x : x + patch_size, y : y + patch_size, z : z + patch_size], axis=0)])\n",
    "# #             result.append(model.predict(input))\n",
    "# #             image.append(input)\n",
    "# #             target.append([np.expand_dims(valid[1][x : x + patch_size, y : y + patch_size, z : z + patch_size], axis=0)])\n",
    "\n",
    "#     input = np.array([np.expand_dims(ndimage.zoom(valid[0], (32/shape[0], 32/shape[1], 32/shape[2])), axis=0)])\n",
    "#     target.append(np.expand_dims(ndimage.zoom(valid[1], (32/shape[0], 32/shape[1], 32/shape[2])), axis=0))\n",
    "#     image.append(input)\n",
    "#     result.append(model.predict(input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
