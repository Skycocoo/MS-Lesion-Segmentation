{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "def fetch_file(pattern=\"\"):\n",
    "    path = os.getcwd() + '/model/h5df_data/'\n",
    "    _, _, files = next(os.walk(path))\n",
    "    result = []\n",
    "    for file in files:\n",
    "        if pattern in file:\n",
    "            result.append(h5py.File(path+file, 'r'))\n",
    "    return result\n",
    "\n",
    "\n",
    "def show_image(images):\n",
    "    # show image with [None, None, : ,: ,:] dimension\n",
    "    def show_frame(id):\n",
    "        length = len(images)\n",
    "        for i in range(length):\n",
    "            ax = plt.subplot(1, length, i+1)\n",
    "            plt.imshow(images[i][id, :, :], cmap='gray')\n",
    "    interact(show_frame, \n",
    "             id=widgets.IntSlider(min=0, max=images[0].shape[0]-1, step=1, value=images[0].shape[0]/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<HDF5 file \"pad_data_T1_preprocessed.h5\" (mode r)>]\n",
      "(128, 256, 256) <HDF5 dataset \"(128, 256, 256)\": shape (5, 128, 256, 256), type \"<f8\">\n",
      "(192, 512, 512) <HDF5 dataset \"(192, 512, 512)\": shape (5, 192, 512, 512), type \"<f8\">\n",
      "(320, 384, 384) <HDF5 dataset \"(320, 384, 384)\": shape (5, 320, 384, 384), type \"<f8\">\n",
      "patch_size <HDF5 dataset \"patch_size\": shape (3,), type \"<i8\">\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7e33ffbd884f8e9333715d2fec7192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=96, description='id', max=191), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = fetch_file(\"pad_data_T1_preprocessed\")\n",
    "print(files)\n",
    "for i in files[0]:\n",
    "    print(i, files[0][i])\n",
    "\n",
    "show_image(files[0][\"(192, 512, 512)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79544355fcd4ec1bb98f1343b43cb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=96, description='id', max=191), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = fetch_file(\"pad_data_T2_preprocessed\")\n",
    "# print(files)\n",
    "# for i in files[0]:\n",
    "#     print(i, files[0][i])\n",
    "\n",
    "show_image(files[0][\"(192, 512, 512)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02c8c4da5594c3e8714d7ca4d6b9b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=96, description='id', max=191), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = fetch_file(\"pad_data_FLAIR\")\n",
    "# print(files)\n",
    "# for i in files[0]:\n",
    "#     print(i, files[0][i])\n",
    "\n",
    "show_image(files[0][\"(192, 512, 512)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<HDF5 file \"pad_target_data.h5\" (mode r)>]\n",
      "(128, 256, 256) <HDF5 dataset \"(128, 256, 256)\": shape (5, 128, 256, 256), type \"<f8\">\n",
      "(192, 512, 512) <HDF5 dataset \"(192, 512, 512)\": shape (5, 192, 512, 512), type \"<f8\">\n",
      "(320, 384, 384) <HDF5 dataset \"(320, 384, 384)\": shape (5, 320, 384, 384), type \"<f8\">\n",
      "patch_size <HDF5 dataset \"patch_size\": shape (3,), type \"<i8\">\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e1f094e5f14103be473ce24b7b4db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=96, description='id', max=191), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = fetch_file(\"pad_target_data\")\n",
    "print(files)\n",
    "for i in files[0]:\n",
    "    print(i, files[0][i])\n",
    "show_image(files[0][\"(192, 512, 512)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.data import *\n",
    "from model.generator import *\n",
    "\n",
    "\n",
    "config = {}\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 2\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "d = Data()\n",
    "d.load_data(config[\"patch_size\"])\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])\n",
    "train_generator = DataGenerator(d.data, d.patch_index, d.kfold, d.batch_size,\n",
    "                                d.patch_size, d.patch_gap, d.valid_index, True)\n",
    "valid_generator = DataGenerator(d.data, d.patch_index, d.kfold, d.batch_size,\n",
    "                                d.patch_size, d.patch_gap, d.valid_index, False)\n",
    "train_generator.set_index(0)\n",
    "valid_generator.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'(128, 256, 256)': array([[[ 16, 128,  32,   0],\n",
      "        [ 32,  16,  32,   0],\n",
      "        [ 32,  96,  48,   0],\n",
      "        ...,\n",
      "        [ 16, 144,  48,   0],\n",
      "        [ 16, 176,  16,   0],\n",
      "        [  0, 160,  64,   0]],\n",
      "\n",
      "       [[ 48,  32,  80,   0],\n",
      "        [ 32, 176, 128,   1],\n",
      "        [  0,   0, 112,   0],\n",
      "        ...,\n",
      "        [ 48,  48, 176,   0],\n",
      "        [ 32,  80,  16,   0],\n",
      "        [ 32,  80,   0,   0]],\n",
      "\n",
      "       [[  0,  80, 176,   1],\n",
      "        [ 16,  32, 128,   1],\n",
      "        [ 32,  32, 160,   1],\n",
      "        ...,\n",
      "        [ 16,  16,  16,   0],\n",
      "        [ 16,  80,  96,   1],\n",
      "        [  0, 128,  80,   1]],\n",
      "\n",
      "       [[ 32, 112, 176,   1],\n",
      "        [ 32, 128, 160,   1],\n",
      "        [ 16, 112, 144,   1],\n",
      "        ...,\n",
      "        [ 16, 112, 128,   1],\n",
      "        [ 16,  80,  96,   1],\n",
      "        [ 48,  80, 128,   1]],\n",
      "\n",
      "       [[ 16,   0,  48,   0],\n",
      "        [ 16,  48,  64,   0],\n",
      "        [ 32, 144,  80,   1],\n",
      "        ...,\n",
      "        [  0, 128,  96,   1],\n",
      "        [ 16, 144,  48,   0],\n",
      "        [ 16,   0,  32,   0]]]), '(192, 512, 512)': array([[[  0, 384, 224,   0],\n",
      "        [ 96, 224, 192,   1],\n",
      "        [ 96, 288, 256,   1],\n",
      "        ...,\n",
      "        [ 80, 368, 384,   0],\n",
      "        [112, 144, 384,   0],\n",
      "        [ 32, 240, 224,   1]],\n",
      "\n",
      "       [[  0, 352, 432,   0],\n",
      "        [112, 112, 240,   0],\n",
      "        [ 32, 208,   0,   0],\n",
      "        ...,\n",
      "        [112,  64, 320,   0],\n",
      "        [ 32, 368, 272,   0],\n",
      "        [112, 368, 384,   0]],\n",
      "\n",
      "       [[ 48, 320,  96,   0],\n",
      "        [ 16, 256, 176,   0],\n",
      "        [ 96, 224, 160,   0],\n",
      "        ...,\n",
      "        [ 32,  48,  32,   0],\n",
      "        [  0, 416, 192,   0],\n",
      "        [ 64, 304,  96,   0]],\n",
      "\n",
      "       [[ 32, 272, 176,   0],\n",
      "        [  0,  16, 112,   0],\n",
      "        [ 16, 384, 304,   0],\n",
      "        ...,\n",
      "        [ 96, 432, 160,   0],\n",
      "        [  0, 272, 368,   0],\n",
      "        [ 32, 368, 272,   1]],\n",
      "\n",
      "       [[ 96, 160, 336,   1],\n",
      "        [ 16, 384,   0,   0],\n",
      "        [ 80, 224, 400,   1],\n",
      "        ...,\n",
      "        [ 48,  16, 320,   0],\n",
      "        [ 80, 368, 384,   1],\n",
      "        [ 64,  48,  80,   0]]]), '(320, 384, 384)': array([[[144, 176, 128,   1],\n",
      "        [ 80, 256,  96,   0],\n",
      "        [  0, 192, 224,   0],\n",
      "        ...,\n",
      "        [128,  64,   0,   0],\n",
      "        [192, 272, 176,   1],\n",
      "        [144,  16, 272,   0]],\n",
      "\n",
      "       [[ 48, 160,  64,   0],\n",
      "        [ 48, 304,  32,   0],\n",
      "        [ 64, 288, 176,   0],\n",
      "        ...,\n",
      "        [ 96, 176, 160,   1],\n",
      "        [208,   0, 224,   0],\n",
      "        [144,  16, 112,   0]],\n",
      "\n",
      "       [[ 16, 272, 112,   0],\n",
      "        [128, 288, 128,   0],\n",
      "        [ 96,  48, 176,   0],\n",
      "        ...,\n",
      "        [160, 192,  96,   0],\n",
      "        [112,  48, 304,   0],\n",
      "        [ 80,  80,  16,   0]],\n",
      "\n",
      "       [[ 96, 112,  48,   0],\n",
      "        [224, 144, 160,   0],\n",
      "        [160,  64, 240,   0],\n",
      "        ...,\n",
      "        [208, 240,   0,   0],\n",
      "        [192, 192,  48,   0],\n",
      "        [ 16,  32, 112,   0]],\n",
      "\n",
      "       [[ 32,  64,  16,   0],\n",
      "        [ 64, 240, 144,   0],\n",
      "        [176, 288, 272,   0],\n",
      "        ...,\n",
      "        [ 16, 240, 128,   0],\n",
      "        [176,  16,  16,   0],\n",
      "        [144,  48, 240,   0]]])})\n"
     ]
    }
   ],
   "source": [
    "print(d.patch_index)\n",
    "# for i, j in d.patch_index.items():\n",
    "#     print(i, j.shape)\n",
    "#     print(d.patch_index[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 64, 64, 64) (2, 1, 64, 64, 64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7d0e43a85043a99a505295645c6302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='id', max=0), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "def fetch_file(pattern=\"\"):\n",
    "    path = os.getcwd() + '/model/h5df_data/'\n",
    "    _, _, files = next(os.walk(path))\n",
    "    result = []\n",
    "    for file in files:\n",
    "        if pattern in file:\n",
    "            result.append(h5py.File(path+file, 'r'))\n",
    "    return result\n",
    "\n",
    "\n",
    "def show_image(images):\n",
    "    # show image with [None, None, : ,: ,:] dimension\n",
    "    def show_frame(id):\n",
    "        length = len(images)\n",
    "        for i in range(length):\n",
    "            ax = plt.subplot(1, length, i+1)\n",
    "            plt.imshow(images[i][id, :, :], cmap='gray')\n",
    "    interact(show_frame, \n",
    "             id=widgets.IntSlider(min=0, max=images[0].shape[0]-1, step=1, value=images[0].shape[0]/2))\n",
    "\n",
    "\n",
    "\n",
    "i = 5\n",
    "inputs = train_generator[i][0]\n",
    "\n",
    "target = train_generator[i][1]\n",
    "print(inputs.shape, target.shape)\n",
    "show_image(inputs[0])\n",
    "print(np.sum(target[0]))\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "# directory: ./data/*/*.nii.gz\n",
    "# there are different modalities that should be taken care of\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.data = defaultdict(list)\n",
    "        self.kfold = None\n",
    "        self.batch_size = None\n",
    "        self.patch_size = None\n",
    "        self.patch_gap = None\n",
    "        self.patch_index = defaultdict(list)\n",
    "        self.valid_index = {}\n",
    "        # pre-set seed so that reconstruct can retrieve valid_index for final result\n",
    "        random.seed(3000)\n",
    "        \n",
    "    def fetch_raw_data(self, raw_path):\n",
    "        def fetch_file():\n",
    "            model = []\n",
    "            seg = []\n",
    "            root, sub_dir, _ = next(os.walk(os.getcwd() + '/data/'))\n",
    "            for sub in sub_dir:\n",
    "                model.append(os.path.join(root, sub + '/FLAIR_preprocessed.nii.gz'))\n",
    "                seg.append(os.path.join(root, sub + '/Consensus.nii.gz'))\n",
    "            return model, seg\n",
    "        \n",
    "        model, seg = fetch_file()\n",
    "        raw_data = defaultdict(list)\n",
    "        # raw_data = []\n",
    "        # raw_data[i][0]: image, raw_data[i][1]: target\n",
    "        for i in range(len(model)):\n",
    "            image = nib.load(model[i])\n",
    "            segment = nib.load(seg[i])\n",
    "            raw_data[image.shape].append([image.get_fdata(), segment.get_fdata()])\n",
    "            # raw_data.append([image.get_fdata(), segment.get_fdata()])\n",
    "        with h5py.File(raw_path, 'w') as f:\n",
    "            # f.create_dataset(\"raw_data\", data=raw_data)\n",
    "            for i in raw_data:\n",
    "                f.create_dataset(str(i), data=raw_data[i])\n",
    "        return self.load_raw_data(raw_path)\n",
    "    \n",
    "    def load_raw_data(self, raw_path):\n",
    "        raw_file = h5py.File(raw_path, 'r') # should not close it immediately\n",
    "        # raw_data = raw_file[\"raw_data\"]\n",
    "        raw_data = defaultdict(list)\n",
    "        for i in raw_file.keys():\n",
    "            # to get the matrix: self.data[i][:]\n",
    "            # d.data[i][j][0], d.data[i][j][1]\n",
    "            raw_data[i] = raw_file[i]\n",
    "        return raw_data, raw_file\n",
    "    \n",
    "    def zero_pad(self, image, div=(32, 32, 32)):\n",
    "        pad_size = [0, 0, 0]\n",
    "        pad = False\n",
    "        for i in range(len(image.shape)):\n",
    "            remain = image.shape[i] % div[i]\n",
    "            if remain != 0:\n",
    "                pad = True\n",
    "                pad_size[i] = (image.shape[i] // div[i] + 1) * div[i] - image.shape[i]\n",
    "        if pad:\n",
    "            # deal with odd number of padding\n",
    "            pad0 = (pad_size[0]//2, pad_size[0] - pad_size[0]//2)\n",
    "            pad1 = (pad_size[1]//2, pad_size[1] - pad_size[1]//2)\n",
    "            pad2 = (pad_size[2]//2, pad_size[2] - pad_size[2]//2)\n",
    "            # https://stackoverflow.com/questions/50008587/zero-padding-a-3d-numpy-array\n",
    "            return np.pad(image, (pad0, pad1, pad2), 'constant')\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        \n",
    "    def pad_raw_data(self, patch_size, pad_path, raw_path):\n",
    "        raw_data = None\n",
    "        raw_file = None\n",
    "        if os.path.isfile(raw_path):\n",
    "            raw_data, raw_file = self.load_raw_data(raw_path)\n",
    "        else:\n",
    "            raw_data, raw_file = self.fetch_raw_data(raw_path)\n",
    "        \n",
    "        # pad_data = []\n",
    "        pad_data = defaultdict(list)\n",
    "        for i in raw_data:\n",
    "            for j in range(raw_data[i].shape[0]):\n",
    "                img = self.zero_pad(raw_data[i][j][0], patch_size)\n",
    "                tar = self.zero_pad(raw_data[i][j][1], patch_size)\n",
    "                pad_data[img.shape].append([img, tar])\n",
    "        raw_file.close()\n",
    "        with h5py.File(pad_path, 'w') as f:\n",
    "            f.create_dataset(\"patch_size\", data=patch_size)\n",
    "            for i in pad_data:\n",
    "                f.create_dataset(str(i), data=pad_data[i])\n",
    "\n",
    "        pad_file = h5py.File(pad_path, 'r')\n",
    "        for i in pad_file.keys():\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            self.data[i] = pad_file[i][:]\n",
    "    \n",
    "    def load_data(self, patch_size=(32, 32, 32), \n",
    "                  pad_path=\"./model/h5df_data/pad_data.h5\", raw_path=\"./model/h5df_data/raw_data.h5\"):\n",
    "        # self.data[image.shape][i][0]: image\n",
    "        # self.data[image.shape][i][1]: segment\n",
    "        if os.path.isfile(pad_path):\n",
    "            pad_file = h5py.File(pad_path, 'r')\n",
    "            if np.all(pad_file[\"patch_size\"][:] == list(patch_size)):\n",
    "                # self.data = pad_file[\"pad_data\"]\n",
    "                for i in pad_file.keys():\n",
    "                    self.data[i] = pad_file[i][:]\n",
    "            else:\n",
    "                pad_file.close()\n",
    "                self.pad_raw_data(patch_size, pad_path, raw_path)\n",
    "        else:\n",
    "            self.pad_raw_data(patch_size, pad_path, raw_path)\n",
    "    \n",
    "    def show_image(self, images):\n",
    "        # show image with [None, None, : ,: ,:] dimension\n",
    "        def show_frame(id):\n",
    "            length = len(images)\n",
    "            for i in range(length):\n",
    "                ax = plt.subplot(1, length, i+1)\n",
    "                if (i == 0):\n",
    "                    ax.set_title(\"Input\")\n",
    "                if (i == 1):\n",
    "                    ax.set_title(\"Target\")\n",
    "                if (i == 2):\n",
    "                    ax.set_title(\"Output\")\n",
    "                plt.imshow(images[i][0, 0, id, :, :], cmap='gray')\n",
    "        interact(show_frame, \n",
    "                 id=widgets.IntSlider(min=0, max=images[0].shape[2]-1, step=1, value=images[0].shape[2]/2))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def gen_patch_index(self, patch_size, patch_gap, index_path):\n",
    "        count = 0\n",
    "        patch_index = defaultdict(list)\n",
    "        # https://arxiv.org/pdf/1710.02316.pdf\n",
    "        # at least 0.01% voxels contain lesions\n",
    "        voxel = int(patch_size[0]*patch_size[1]*patch_size[2]*0.0001)\n",
    "        \n",
    "        for i in self.data:\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            shape = self.data[i][0][0].shape\n",
    "            patch_num = [int((shape[i]-patch_size[i]) / patch_gap) for i in range(len(shape))]\n",
    "\n",
    "            for j in range(self.data[i].shape[0]):\n",
    "                patch_ind = []\n",
    "                # assume this is a 3d image\n",
    "                for a in range(patch_num[0]):\n",
    "                    for b in range(patch_num[1]):\n",
    "                        for c in range(patch_num[2]):\n",
    "                            patch_iter = [a * patch_gap, b * patch_gap, c * patch_gap, 1]\n",
    "                            if (np.sum(self.data[i][j][1][patch_iter[0]:patch_iter[0] + patch_size[0],\n",
    "                                                          patch_iter[1]:patch_iter[1] + patch_size[1],\n",
    "                                                          patch_iter[2]:patch_iter[2] + patch_size[2]]) <= voxel):\n",
    "                                # 0: does not satisfy, need to skip when generating\n",
    "                                patch_iter[3] = 0\n",
    "                            patch_ind.append(patch_iter)\n",
    "                patch_index[i].append(patch_ind)\n",
    "            \n",
    "            for c in range(len(patch_index[i])):\n",
    "                # in-place shuffle\n",
    "                np.random.shuffle(patch_index[i][c])\n",
    "\n",
    "            # total number of patches for this shape\n",
    "            count += len(patch_ind) * self.data[i].shape[0]\n",
    "        \n",
    "        with h5py.File(index_path, 'w') as f:\n",
    "            f.create_dataset(\"count\", data=count)\n",
    "            f.create_dataset(\"patch_size\", data=patch_size)\n",
    "            f.create_dataset(\"patch_gap\", data=patch_gap)\n",
    "            for i in patch_index:\n",
    "                f.create_dataset(str(i), data=patch_index[i])\n",
    "        \n",
    "        index_file = h5py.File(index_path, 'r')\n",
    "        for i in index_file.keys():\n",
    "            if i == \"count\" or i == \"patch_size\" or i == \"patch_gap\":\n",
    "                continue\n",
    "            self.patch_index[i] = index_file[i][:]\n",
    "        # return the total number of patches\n",
    "        return index_file[\"count\"][()]\n",
    "\n",
    "    def load_patch_index(self, patch_size, patch_gap, index_path):\n",
    "        if os.path.isfile(index_path):\n",
    "            index_file = h5py.File(index_path, 'r')\n",
    "            # print(list(pat_ind.keys()))\n",
    "            if (np.all(index_file[\"patch_size\"][:] == list(patch_size))) and (index_file[\"patch_gap\"][()] == patch_gap):\n",
    "                for i in index_file.keys():\n",
    "                    if i == \"count\" or i == \"patch_size\" or i == \"patch_gap\":\n",
    "                        continue\n",
    "                    self.patch_index[i] = index_file[i][:]\n",
    "                return index_file[\"count\"][()]\n",
    "            else:\n",
    "                index_file.close()\n",
    "                return self.gen_patch_index(patch_size, patch_gap, index_path)\n",
    "        else:\n",
    "            return self.gen_patch_index(patch_size, patch_gap, index_path)\n",
    "            \n",
    "    def prekfold(self, patch_size, patch_gap, batch_size, kfold=5, index_path='./model/h5df_data/pat_ind.h5'):\n",
    "        self.kfold = kfold\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_gap = patch_gap\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # initialize validation index for training\n",
    "        # K-fold LOOCV: leave one out cross validation\n",
    "        for i in self.data:\n",
    "            if i == \"patch_size\":\n",
    "                continue\n",
    "            self.valid_index[i] = random.sample(range(self.kfold), self.kfold)\n",
    "\n",
    "        num = self.load_patch_index(patch_size, patch_gap, index_path)\n",
    "        train_num = num // self.kfold * (self.kfold - 1)\n",
    "        valid_num = num - train_num\n",
    "        \n",
    "        return train_num // batch_size, valid_num // batch_size\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 2\n",
    "config[\"kfold\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Data()\n",
    "d.load_data(config[\"patch_size\"])\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.generator import *\n",
    "train_generator = DataGenerator(d.data, d.patch_index, d.kfold, d.batch_size, \n",
    "                                d.patch_size, d.patch_gap, d.valid_index, True)\n",
    "valid_generator = DataGenerator(d.data, d.patch_index, d.kfold, d.batch_size, \n",
    "                                d.patch_size, d.patch_gap, d.valid_index, False)\n",
    "train_generator.set_index(0)\n",
    "valid_generator.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26496 6624\n",
      "defaultdict(<class 'list'>, {'(128, 256, 256)': array([[[  0, 160,  32,   0],\n",
      "        [ 48,   0,  96,   0],\n",
      "        [ 16,  32,  48,   0],\n",
      "        ...,\n",
      "        [ 48,  96,  48,   0],\n",
      "        [ 48,  32,  16,   0],\n",
      "        [ 32,  32,   0,   0]],\n",
      "\n",
      "       [[ 16, 176,  16,   0],\n",
      "        [  0,  32,  16,   0],\n",
      "        [ 16,  16,  96,   0],\n",
      "        ...,\n",
      "        [ 32,  96, 128,   1],\n",
      "        [ 48,  80,   0,   0],\n",
      "        [  0, 176, 128,   1]],\n",
      "\n",
      "       [[ 48,  64,  64,   1],\n",
      "        [ 48, 128,  32,   0],\n",
      "        [ 32,   0, 160,   0],\n",
      "        ...,\n",
      "        [  0, 112,  96,   1],\n",
      "        [ 16, 112,  64,   1],\n",
      "        [ 16,  80, 128,   1]],\n",
      "\n",
      "       [[ 16, 144,  80,   1],\n",
      "        [  0,  32,   0,   0],\n",
      "        [ 16, 144,  16,   0],\n",
      "        ...,\n",
      "        [  0,  32,  16,   0],\n",
      "        [ 48, 128, 112,   1],\n",
      "        [ 16, 176, 128,   1]],\n",
      "\n",
      "       [[ 48,   0,  16,   0],\n",
      "        [  0,   0,   0,   0],\n",
      "        [  0,  96,  64,   0],\n",
      "        ...,\n",
      "        [ 32,  80, 176,   1],\n",
      "        [ 48,  32,  48,   0],\n",
      "        [ 32,  16,  80,   0]]]), '(192, 512, 512)': array([[[ 80, 144, 224,   0],\n",
      "        [ 80, 288, 256,   1],\n",
      "        [ 80, 416, 320,   0],\n",
      "        ...,\n",
      "        [ 64, 144, 272,   1],\n",
      "        [ 48, 336, 144,   0],\n",
      "        [ 48, 384, 288,   1]],\n",
      "\n",
      "       [[ 48, 320, 352,   0],\n",
      "        [  0, 416, 400,   0],\n",
      "        [ 48, 352, 416,   0],\n",
      "        ...,\n",
      "        [ 64, 208,  96,   0],\n",
      "        [  0,  80, 368,   0],\n",
      "        [ 96, 336, 400,   0]],\n",
      "\n",
      "       [[ 96,  16, 128,   0],\n",
      "        [ 32, 176,  64,   0],\n",
      "        [ 32, 128, 336,   0],\n",
      "        ...,\n",
      "        [  0,  64, 320,   0],\n",
      "        [ 32, 128, 256,   0],\n",
      "        [ 96,  16, 320,   0]],\n",
      "\n",
      "       [[  0, 144,  96,   0],\n",
      "        [ 80, 176,  48,   0],\n",
      "        [ 48, 352,  64,   0],\n",
      "        ...,\n",
      "        [ 64, 320, 432,   0],\n",
      "        [ 64, 288, 416,   0],\n",
      "        [  0, 208, 384,   0]],\n",
      "\n",
      "       [[ 64,  64, 144,   0],\n",
      "        [ 64, 416, 352,   0],\n",
      "        [ 96, 192, 288,   1],\n",
      "        ...,\n",
      "        [ 48, 160,  80,   0],\n",
      "        [ 48, 400,   0,   0],\n",
      "        [ 96, 320,  80,   0]]]), '(320, 384, 384)': array([[[ 80, 160,  64,   0],\n",
      "        [176, 160, 224,   1],\n",
      "        [112, 288, 272,   0],\n",
      "        ...,\n",
      "        [ 48,  64, 112,   0],\n",
      "        [ 64,  48, 304,   0],\n",
      "        [144, 304,  80,   0]],\n",
      "\n",
      "       [[112, 192, 144,   1],\n",
      "        [ 64, 304, 256,   0],\n",
      "        [240, 192,  96,   0],\n",
      "        ...,\n",
      "        [ 16,  96, 192,   0],\n",
      "        [ 32, 192, 224,   0],\n",
      "        [176, 304,  64,   0]],\n",
      "\n",
      "       [[240,  48, 144,   0],\n",
      "        [112, 128,  48,   0],\n",
      "        [  0,  16,  96,   0],\n",
      "        ...,\n",
      "        [112, 288, 208,   1],\n",
      "        [ 16, 192,  48,   0],\n",
      "        [144, 240, 256,   1]],\n",
      "\n",
      "       [[ 80, 112, 272,   1],\n",
      "        [128, 224, 304,   0],\n",
      "        [ 80, 256, 256,   1],\n",
      "        ...,\n",
      "        [ 48, 256,  48,   0],\n",
      "        [ 64, 176, 144,   0],\n",
      "        [240,   0,  80,   0]],\n",
      "\n",
      "       [[ 96, 160,  96,   0],\n",
      "        [112,  48,  32,   0],\n",
      "        [ 64,  64, 272,   0],\n",
      "        ...,\n",
      "        [112, 112, 160,   0],\n",
      "        [ 48, 128,  80,   0],\n",
      "        [ 48, 176,  32,   0]]])})\n"
     ]
    }
   ],
   "source": [
    "print(train_num, valid_num)\n",
    "print(d.patch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "def fetch_file(pattern=\"\"):\n",
    "    path = os.getcwd() + '/model/h5df_data/'\n",
    "    _, _, files = next(os.walk(path))\n",
    "    result = []\n",
    "    for file in files:\n",
    "        if pattern in file:\n",
    "            result.append(h5py.File(path+file, 'r'))\n",
    "    return result\n",
    "\n",
    "\n",
    "def show_image(images):\n",
    "    # show image with [None, None, : ,: ,:] dimension\n",
    "    def show_frame(id):\n",
    "        length = len(images)\n",
    "        for i in range(length):\n",
    "            ax = plt.subplot(1, length, i+1)\n",
    "            plt.imshow(images[i][id, :, :], cmap='gray')\n",
    "    interact(show_frame, \n",
    "             id=widgets.IntSlider(min=0, max=images[0].shape[0]-1, step=1, value=images[0].shape[0]/2))\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 64, 64, 64) (2, 1, 64, 64, 64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d80473d20d4b949966aaffa165d636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=32, description='id', max=63), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34631.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 3000\n",
    "inputs = train_generator[i][0]\n",
    "\n",
    "target = train_generator[i][1]\n",
    "print(inputs.shape, target.shape)\n",
    "show_image(inputs[0])\n",
    "print(np.sum(target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
