{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reference: https://github.com/ellisdg/3DUnetCNN/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 5\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "config[\"input_shape\"] = (1, None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data import *\n",
    "from model.model import *\n",
    "\n",
    "d = Data()\n",
    "d.load_data()\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 1/10\n",
      " 10/500 [..............................] - ETA: 23:21 - loss: 0.3490 - dice_coefficient: 0.6510"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "target = []\n",
    "image = []\n",
    "\n",
    "def train(config, data, train_num, valid_num):\n",
    "#     models = []\n",
    "\n",
    "    print(train_num, valid_num)\n",
    "    for i in range(data.kfold):\n",
    "        print ('-'*100)\n",
    "        print (\"Fold:\", i)\n",
    "        model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "        \n",
    "        # print(model.summary())\n",
    "        \n",
    "        callbacks = get_callbacks(config[\"weights_file\"],\n",
    "                                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                                learning_rate_patience=config[\"patience\"],\n",
    "                                early_stopping_patience=config[\"early_stop\"])\n",
    "\n",
    "        model.fit_generator(generator=data.train_generator(i, batch_size=config[\"batch_size\"]),\n",
    "                            steps_per_epoch=train_num,\n",
    "                            epochs=config[\"n_epochs\"],\n",
    "                            validation_data=data.valid_generator(i),\n",
    "                            validation_steps=valid_num,\n",
    "                            callbacks=callbacks,\n",
    "                            verbose=1)\n",
    "        break\n",
    "train(config, d, 200, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipywidgets as widgets\n",
    "# from ipywidgets import interact, interactive\n",
    "\n",
    "# def show_image(images):\n",
    "#     def show_frame(id):\n",
    "#         length = len(images)\n",
    "#         for i in range(length):\n",
    "#             plt.subplot(1, length, i+1)\n",
    "#             plt.imshow(images[i][0, 0, id, :, :], cmap='gray')\n",
    "#     interact(show_frame, id=widgets.IntSlider(min=0, max=images[0].shape[2]-1, step=1, value=images[0].shape[2]/2))\n",
    "\n",
    "# sel = next(iter(d.valid_index))\n",
    "# show_image([result[0], image[0][None, :, :, :, :], target[0][None, :, :, :, :]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice = 0\n",
    "# for i in range(len(result)):\n",
    "#     dice += dice_coefficient(target[i], result[i])\n",
    "\n",
    "# print(\"dice:\", dice / len(result))\n",
    "# print(\"loss:\", 1 - dice / len(result)) \n",
    "\n",
    "# print(dice_coefficient(target, result))\n",
    "# print(np.array(result).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "#                               pool_size=config[\"pool_size\"],\n",
    "#                               initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "#                               deconvolution=config[\"deconvolution\"],\n",
    "#                               depth=config[\"depth\"],\n",
    "#                               n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "# model.load_weights(os.getcwd() + '/model/weight/weights-10--1.00.hdf5.h5')\n",
    "\n",
    "# for j in d.valid_index:\n",
    "#     valid = d.data[j][0] # fold = 0\n",
    "#     shape = valid[0].shape\n",
    "# #             x = shape[0] // 2\n",
    "# #             y = shape[1] // 2\n",
    "# #             z = shape[2] // 2\n",
    "# #             input = np.array([np.expand_dims(valid[0][x : x + patch_size, y : y + patch_size, z : z + patch_size], axis=0)])\n",
    "# #             result.append(model.predict(input))\n",
    "# #             image.append(input)\n",
    "# #             target.append([np.expand_dims(valid[1][x : x + patch_size, y : y + patch_size, z : z + patch_size], axis=0)])\n",
    "\n",
    "#     input = np.array([np.expand_dims(ndimage.zoom(valid[0], (32/shape[0], 32/shape[1], 32/shape[2])), axis=0)])\n",
    "#     target.append(np.expand_dims(ndimage.zoom(valid[1], (32/shape[0], 32/shape[1], 32/shape[2])), axis=0))\n",
    "#     image.append(input)\n",
    "#     result.append(model.predict(input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
