{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 10\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "config[\"input_shape\"] = (1, None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.data import *\n",
    "from model.model import *\n",
    "\n",
    "d = Data()\n",
    "d.load_data()\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "model.load_weights(os.getcwd() + '/model/weight/weights-01-0.00.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## need to have a way to merge all patches for testing the resulting weights ##############\n",
    "\n",
    "image = []\n",
    "target = []\n",
    "result = []\n",
    "indices = None\n",
    "shape = None\n",
    "fold_index = 0\n",
    "for i in d.valid_index:\n",
    "    j = d.valid_index[i][fold_index]\n",
    "    indices = d.patch_index[i][j]\n",
    "    shape = d.data[i][j][0].shape\n",
    "    for ind in range(d.patch_index[i].shape[1]):\n",
    "        patch = d.patch_index[i][j][ind]\n",
    "        image_i = np.expand_dims(d.data[i][j][0][patch[0]:patch[0]+d.patch_size[0], \n",
    "                         patch[1]:patch[1]+d.patch_size[1], \n",
    "                         patch[2]:patch[2]+d.patch_size[2]], axis=0)\n",
    "        target_i = np.expand_dims(d.data[i][j][1][patch[0]:patch[0]+d.patch_size[0], \n",
    "                         patch[1]:patch[1]+d.patch_size[1], \n",
    "                         patch[2]:patch[2]+d.patch_size[2]], axis=0)\n",
    "        image.append(image_i)\n",
    "        target.append(target_i)\n",
    "        result.append(model.predict([image_i[None, :]]))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_from_patches(patches, patch_indices, data_shape, default_value=0):\n",
    "    \"\"\"\n",
    "    Reconstructs an array of the original shape from the lists of patches and corresponding patch indices. Overlapping\n",
    "    patches are averaged.\n",
    "    :param patches: List of numpy array patches.\n",
    "    :param patch_indices: List of indices that corresponds to the list of patches.\n",
    "    :param data_shape: Shape of the array from which the patches were extracted.\n",
    "    :param default_value: The default value of the resulting data. if the patch coverage is complete, this value will\n",
    "    be overwritten.\n",
    "    :return: numpy array containing the data reconstructed by the patches.\n",
    "    \"\"\"\n",
    "    data = np.ones(data_shape) * default_value\n",
    "    image_shape = data_shape[-3:]\n",
    "    count = np.zeros(data_shape, dtype=np.int)\n",
    "    for patch, index in zip(patches, patch_indices):\n",
    "        image_patch_shape = patch.shape[-3:]\n",
    "        patch_index = np.zeros(data_shape, dtype=np.bool)\n",
    "        patch_index[...,\n",
    "                    index[0]:index[0]+patch.shape[-3],\n",
    "                    index[1]:index[1]+patch.shape[-2],\n",
    "                    index[2]:index[2]+patch.shape[-1]] = True\n",
    "        patch_data = np.zeros(data_shape)\n",
    "        \n",
    "        patch_data[patch_index] = patch.flatten()\n",
    "\n",
    "        new_data_index = np.logical_and(patch_index, np.logical_not(count > 0))\n",
    "        data[new_data_index] = patch_data[new_data_index]\n",
    "\n",
    "        averaged_data_index = np.logical_and(patch_index, count > 0)\n",
    "        if np.any(averaged_data_index):\n",
    "            data[averaged_data_index] = (data[averaged_data_index] * count[averaged_data_index] + patch_data[averaged_data_index]) / (count[averaged_data_index] + 1)\n",
    "        count[patch_index] += 1\n",
    "    return data\n",
    "\n",
    "\n",
    "merge_image = reconstruct_from_patches(image, indices, shape[-3:])\n",
    "merge_target = reconstruct_from_patches(target, indices, shape[-3:])\n",
    "merge_result = reconstruct_from_patches(result, indices, shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.show_image([merge_image, merge_target, merge_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "target = []\n",
    "result = []\n",
    "\n",
    "count = 0\n",
    "for img, tar in d.valid_generator(0):\n",
    "    if count == 20:\n",
    "        break\n",
    "    image.append(img)\n",
    "    target.append(tar)\n",
    "    result.append(model.predict(img))\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3db6d40d4f44d4b555bcaa66e8b09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=32, description='id', max=63), Output()), _dom_classes=('widget-interactâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: 0.0\n",
      "result: 0.00013920286\n",
      "0.026672928987640735\n",
      "[0.0000000e+00 1.1769894e-38 1.1810282e-38 ... 3.5310113e-01 3.5785753e-01\n",
      " 3.6344498e-01]\n"
     ]
    }
   ],
   "source": [
    "sel = 13\n",
    "d.show_image([image[sel], target[sel], result[sel]>0])\n",
    "print(\"target:\", np.mean(target[sel]))\n",
    "print(\"result:\", np.mean(result[sel]))\n",
    "print(dice_coefficient(target[sel], result[sel]))\n",
    "\n",
    "print(np.unique(result[sel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
