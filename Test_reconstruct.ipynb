{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = {}\n",
    "config[\"weights_file\"] = os.getcwd() + '/model/weight'\n",
    "config[\"patch_size\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"patch_gap\"] = 16\n",
    "config[\"batch_size\"] = 10\n",
    "config[\"kfold\"] = 5\n",
    "\n",
    "config[\"input_shape\"] = (1, None, None, None)\n",
    "config[\"depth\"] = 4 # depth of layers for V/Unet\n",
    "config[\"n_base_filters\"] = 32\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 10  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"n_epochs\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.data import *\n",
    "from model.model import *\n",
    "\n",
    "d = Data()\n",
    "d.load_data(config[\"patch_size\"])\n",
    "\n",
    "# prepare data for training\n",
    "train_num, valid_num = d.prekfold(config[\"patch_size\"], config[\"patch_gap\"], config[\"batch_size\"], config[\"kfold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"],\n",
    "                              depth=config[\"depth\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"])\n",
    "\n",
    "weight_path = '/model/weight/ref/weights-02-0.02-0429-binary-patch.hdf5'\n",
    "model.load_weights(os.getcwd() + weight_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "\n",
    "class Reconstruct:\n",
    "    def __init__(self, ind, shape, patch_size, to_weight):\n",
    "        # find its original image: d.data[str(shape)][ind][0]\n",
    "        # find its target image: d.data[str(shape)][ind][1]\n",
    "        self.ind = ind\n",
    "        self.shape = shape\n",
    "        self.patch_size = patch_size\n",
    "        # weight the patch before merging or not\n",
    "        self.to_weight = to_weight\n",
    "        \n",
    "        self.data = np.zeros(shape)\n",
    "        self.image = np.zeros(shape)\n",
    "        self.target = np.zeros(shape)\n",
    "        self.count = np.zeros(shape, dtype=np.float32)\n",
    "        \n",
    "#         construct softmax map for distance from the boundary\n",
    "\n",
    "        if self.to_weight is False:\n",
    "            self.dist_map = np.ones(patch_size)\n",
    "        else:\n",
    "            self.dist_map = np.zeros(patch_size)\n",
    "            mini = 0\n",
    "            minj = 0\n",
    "            mink = 0\n",
    "            for i in range(patch_size[0]):\n",
    "                mini = min(i+1, patch_size[0]-i)\n",
    "                for j in range(patch_size[1]):\n",
    "                    minj = min(j+1, patch_size[1]-j)\n",
    "                    for k in range(patch_size[2]):\n",
    "                        mink = min(k+1, patch_size[2]-k)\n",
    "    #                     print(i, j, k, mini, minj, mink)\n",
    "                        self.dist_map[i, j, k] = min(mini, minj, mink)\n",
    "    #         print(self.dist_map)\n",
    "            self.dist_map = np.exp(self.dist_map)/np.sum(np.exp(self.dist_map))\n",
    "    \n",
    "#             self.dist_map = np.zeros(patch_size)\n",
    "#             center = (np.array(patch_size)-1) / 2\n",
    "#             center_dist = np.linalg.norm(center)\n",
    "#             for i in range(patch_size[0]):\n",
    "#                 for j in range(patch_size[1]):\n",
    "#                     for k in range(patch_size[2]):\n",
    "#     #                     print([i, j, k], np.array([i, j, k]) - center)\n",
    "#                         self.dist_map[i, j, k] = center_dist - np.linalg.norm(np.array([i, j, k]) - center)\n",
    "#     #         print(self.dist_map)\n",
    "#             self.dist_map[self.dist_map < 0] = 0\n",
    "#             self.dist_map = np.exp(self.dist_map)/np.sum(np.exp(self.dist_map))\n",
    "#     #         print(self.dist_map)\n",
    "\n",
    "        \n",
    "    def add(self, patch, index):\n",
    "        patch = patch * self.dist_map\n",
    "        # get patch data\n",
    "        patch_index = np.zeros(self.shape, dtype=np.bool)\n",
    "        patch_index[...,\n",
    "                    index[0]:index[0]+patch.shape[-3],\n",
    "                    index[1]:index[1]+patch.shape[-2],\n",
    "                    index[2]:index[2]+patch.shape[-1]] = True\n",
    "        patch_data = np.zeros(self.shape)\n",
    "        patch_data[patch_index] = patch.flatten()\n",
    "        \n",
    "        # store patch data in self.data\n",
    "        new_data_index = np.logical_and(patch_index, np.logical_not(self.count > 0))\n",
    "        self.data[new_data_index] = patch_data[new_data_index]\n",
    "        \n",
    "        # average overlapped region\n",
    "        averaged_data_index = np.logical_and(patch_index, self.count > 0)\n",
    "        if np.any(averaged_data_index):\n",
    "            self.data[averaged_data_index] = (self.data[averaged_data_index] * self.count[averaged_data_index] + \n",
    "                                              patch_data[averaged_data_index]) / (self.count[averaged_data_index] + 1)\n",
    "#         self.count[patch_index] += 1\n",
    "#         print(self.count[patch_index].shape, self.dist_map.shape)\n",
    "        self.count[ index[0]:index[0]+patch.shape[-3],\n",
    "                    index[1]:index[1]+patch.shape[-2],\n",
    "                    index[2]:index[2]+patch.shape[-1]] += 1\n",
    "        \n",
    "    def store(self, name):\n",
    "        with h5py.File(\"./model/h5df_data/reconstruct_\" + name + \"_\" +  str(self.shape) + \".h5\", 'w') as f:\n",
    "            f.create_dataset(\"index\", data=self.ind)\n",
    "            f.create_dataset(\"shape\", data=self.shape)\n",
    "            f.create_dataset(\"data\", data=self.data)\n",
    "        nib.save(nib.Nifti1Image(self.data, np.eye(4)), \"reconstruct_\" + name + str(i.shape) + \".nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_index = 0\n",
    "recon = []\n",
    "for i in d.valid_index:\n",
    "    j = d.valid_index[i][fold_index]\n",
    "    recons = Reconstruct(j, d.data[i][j][0].shape, config[\"patch_size\"], True)\n",
    "    orig = Reconstruct(j, d.data[i][j][0].shape, config[\"patch_size\"], False)\n",
    "    for ind in range(d.patch_index[i][j].shape[0]):\n",
    "        index = d.patch_index[i][j][ind]\n",
    "        image_i = np.expand_dims(d.data[i][j][0][\n",
    "                         index[0]:index[0]+d.patch_size[0], \n",
    "                         index[1]:index[1]+d.patch_size[1], \n",
    "                         index[2]:index[2]+d.patch_size[2]], axis=0)\n",
    "        result = model.predict([image_i[None, :]])\n",
    "        recons.add(result, index)\n",
    "        orig.add(result, index)\n",
    "    recon.append(recons)\n",
    "    recon.append(orig)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e80f19c83466ea86ee3116bac9c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=64, description='id', max=127), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image([recon[0].data, recon[1].data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb08bff609c54c50a6e93aaa2dc788c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='id', max=4), Output()), _dom_classes=('widget-interact',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "size = 5\n",
    "res = Reconstruct(0, (size, size, size), (size, size, size), False)\n",
    "print(res.dist_map)\n",
    "\n",
    "def show_image(images):\n",
    "    # show image with [None, None, : ,: ,:] dimension\n",
    "    def show_frame(id):\n",
    "        length = len(images)\n",
    "        for i in range(length):\n",
    "            ax = plt.subplot(1, length, i+1)\n",
    "            plt.imshow(images[i][id, :, :], cmap='gray')\n",
    "    interact(show_frame, \n",
    "             id=widgets.IntSlider(min=0, max=images[0].shape[0]-1, step=1, value=images[0].shape[0]/2))\n",
    "        \n",
    "show_image([res.dist_map])\n",
    "# print(2 * np.ones((3,3,3)) * res.dist_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full_img2(model, device, test_data, save_folder, save_name, box_size=160, save_thresh = 0.75):\n",
    "    model.eval()\n",
    "    img_num = 1\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        img, sub_box = test_data\n",
    "\n",
    "        predict_subbox = []\n",
    "\n",
    "        test_whole_volumes = {}\n",
    "        test_whole_labels = {}\n",
    "        for i in range(1):\n",
    "            test_whole_volumes[i] = img\n",
    "            test_whole_labels[i] = img\n",
    "\n",
    "        test_idx = list(range(1))\n",
    "        test_sub_box = get_subbox_idx(test_idx,[(img, sub_box)])\n",
    "\n",
    "        test_Mouse_dataset = Mouse_sub_volumes_test(test_whole_volumes,test_whole_labels,test_sub_box)\n",
    "        test_dataloader = DataLoader(test_Mouse_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "        for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label'].numpy()\n",
    "            outputs = model(inputs.to(device)).cpu().numpy()\n",
    "            for i_subimg in range(outputs.shape[0]):\n",
    "                predict_subbox.append(np.squeeze(outputs[i_subimg,...]))\n",
    "                \n",
    "        y_predict = np.zeros((np.shape(img)),np.float32)\n",
    "        overlapping = np.zeros((np.shape(img)),np.float32)\n",
    "        \n",
    "        box_one = np.ones((box_size,box_size,box_size),np.float32) * 0.2\n",
    "        box_one[20:140, 20:140, 20:140] = 1.0\n",
    "\n",
    "        for i_subbox in range(len(sub_box)):\n",
    "            x, y, z = sub_box[i_subbox]\n",
    "            y_predict[x-box_size:x, y-box_size:y, z-box_size:z] += predict_subbox[i_subbox] * box_one\n",
    "            overlapping[x-box_size:x, y-box_size:y, z-box_size:z] += box_one\n",
    "            \n",
    "\n",
    "        y_predict /= overlapping\n",
    "        \n",
    "        y_predict[y_predict >  save_thresh] = 1.0\n",
    "        y_predict[y_predict <= save_thresh] = 0.0\n",
    "\n",
    "        max_component = 1\n",
    "        y_predict_component = measure.label(y_predict)\n",
    "        component_num = np.unique(y_predict_component)\n",
    "        for current_component in range(1,len(component_num)):\n",
    "            if np.sum(y_predict_component == current_component) < np.sum(y_predict_component == max_component):\n",
    "                y_predict[y_predict_component == current_component] = 0\n",
    "            elif np.sum(y_predict_component == current_component) > np.sum(y_predict_component == max_component):\n",
    "                y_predict[y_predict_component == max_component] = 0\n",
    "                max_component = current_component\n",
    "\n",
    "        y_predict = ndimage.binary_fill_holes(y_predict).astype(float)\n",
    "\n",
    "        \n",
    "        save_nii(img, y_predict, save_folder, save_name)\n",
    "\n",
    "        #print('Img_num: {}, f-score: {}'.format(img_num, score))\n",
    "        print('img {}, predict body pixel: {}'.format(img_num, np.sum(y_predict)))\n",
    "        img_num += 1\n",
    "        del y_predict\n",
    "        #print('average score of {} images is {}'.format(test_img, score_sum/test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<HDF5 file \"reconstruct_dice_softmax_circle_(192, 512, 512).h5\" (mode r)>, <HDF5 file \"reconstruct_dice_softmax_circle_(320, 384, 384).h5\" (mode r)>, <HDF5 file \"reconstruct_dice_softmax_circle_(128, 256, 256).h5\" (mode r)>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "def fetch_file():\n",
    "    path = os.getcwd() + '/model/h5df_data/'\n",
    "    _, _, files = next(os.walk(path))\n",
    "    result = []\n",
    "    for file in files:\n",
    "        if \"reconstruct_dice_softmax_circle_\" in file:\n",
    "            result.append(h5py.File(path+file, 'r'))\n",
    "    return result\n",
    "            \n",
    "files = fetch_file()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in files:\n",
    "    images.append(i[\"data\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7122dbbe27d493bbf98770b01f453f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=96, description='id', max=191), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model.data import *\n",
    "\n",
    "print(np.array(images).shape)\n",
    "d = Data()\n",
    "d.show_image([images[0][None, None, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all files to nii\n",
    "def store_nii(arr):\n",
    "    for i in arr:\n",
    "        nib.save(nib.Nifti1Image(i, np.eye(4)), \"reconstruct\" + str(i.shape) + \".nii.gz\")\n",
    "    \n",
    "store_nii(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import h5py\n",
    "\n",
    "# class Reconstruct:\n",
    "#     def __init__(self, ind, shape, patch_size):\n",
    "#         # find its original image: d.data[str(shape)][ind][0]\n",
    "#         # find its target image: d.data[str(shape)][ind][1]\n",
    "#         self.ind = ind\n",
    "#         self.shape = shape\n",
    "#         self.patch_size = patch_size\n",
    "#         self.data = np.zeros(shape)\n",
    "#         self.count = np.zeros(shape, dtype=np.int)\n",
    "        \n",
    "# #         construct softmax map for distance from the boundary\n",
    "#         self.dist_map = np.zeros(patch_size)\n",
    "#         mini = 0\n",
    "#         minj = 0\n",
    "#         mink = 0\n",
    "#         for i in range(patch_size[0]):\n",
    "#             mini = min(i+1, patch_size[0]-i)\n",
    "#             for j in range(patch_size[1]):\n",
    "#                 minj = min(j+1, patch_size[1]-j)\n",
    "#                 for k in range(patch_size[2]):\n",
    "#                     mink = min(k+1, patch_size[2]-k)\n",
    "# #                     print(i, j, k, mini, minj, mink)\n",
    "#                     self.dist_map[i, j, k] = min(mini, minj, mink)\n",
    "# #         print(self.dist_map)\n",
    "#         # add a base weight to have a bit more weight on the margins\n",
    "# #         self.dist_map += 32\n",
    "#         self.dist_map = np.exp(self.dist_map)/np.sum(np.exp(self.dist_map))\n",
    "\n",
    "# #         self.dist_map = np.zeros(patch_size)\n",
    "# #         center = (np.array(patch_size)-1) / 2\n",
    "# #         center_dist = np.linalg.norm(center)\n",
    "# #         for i in range(patch_size[0]):\n",
    "# #             for j in range(patch_size[1]):\n",
    "# #                 for k in range(patch_size[2]):\n",
    "# # #                     print([i, j, k], np.array([i, j, k]) - center)\n",
    "# #                     self.dist_map[i, j, k] = center_dist - np.linalg.norm(np.array([i, j, k]) - center)\n",
    "# # #         print(self.dist_map)\n",
    "# #         self.dist_map[self.dist_map < 0] = 0\n",
    "# #         self.dist_map = np.exp(self.dist_map)/np.sum(np.exp(self.dist_map))\n",
    "# # #         print(self.dist_map)\n",
    "\n",
    "        \n",
    "#     def add(self, patch, index):\n",
    "#         patch = patch * self.dist_map\n",
    "#         # get patch data\n",
    "#         patch_index = np.zeros(self.shape, dtype=np.bool)\n",
    "#         patch_index[...,\n",
    "#                     index[0]:index[0]+patch.shape[-3],\n",
    "#                     index[1]:index[1]+patch.shape[-2],\n",
    "#                     index[2]:index[2]+patch.shape[-1]] = True\n",
    "#         patch_data = np.zeros(self.shape)\n",
    "#         patch_data[patch_index] = patch.flatten()\n",
    "        \n",
    "#         # store patch data in self.data\n",
    "#         new_data_index = np.logical_and(patch_index, np.logical_not(self.count > 0))\n",
    "#         self.data[new_data_index] = patch_data[new_data_index]\n",
    "        \n",
    "#         # average overlapped region\n",
    "#         averaged_data_index = np.logical_and(patch_index, self.count > 0)\n",
    "#         if np.any(averaged_data_index):\n",
    "#             self.data[averaged_data_index] = (self.data[averaged_data_index] * self.count[averaged_data_index] + \n",
    "#                                               patch_data[averaged_data_index]) / (self.count[averaged_data_index] + 1)\n",
    "#         self.count[patch_index] += 1\n",
    "        \n",
    "#     def store(self, name):\n",
    "#         with h5py.File(\"./model/h5df_data/reconstruct_\" + name + \"_\" +  str(self.shape) + \".h5\", 'w') as f:\n",
    "#             f.create_dataset(\"index\", data=self.ind)\n",
    "#             f.create_dataset(\"shape\", data=self.shape)\n",
    "#             f.create_dataset(\"data\", data=self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
